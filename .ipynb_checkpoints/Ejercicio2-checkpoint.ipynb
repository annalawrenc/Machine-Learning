{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Implementación de una regresión “stepwise” con eliminación hacia atrás."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando como referencia el código del algoritmo “stepwise” con selección hacia adelante(Fordward Stepwise Regression) realizar una implementación del del algoritmo con eliminación hacia atrás (Backward Stepwise Regression). \n",
    "\n",
    "En este caso la selección de las variables se realiza empezando con un modelo que utiliza todas la variables disponibles para ir eliminando en cada paso la produce el modelo menos significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fordward Stepwise Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def forward_regression(x, y):\n",
    "    # Obtencion del conjunto de datos para validación\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    # Modelo para realizar los ajustes\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Variable para almecena los índices de la lista de atributos usados\n",
    "    feature_list = list(x.columns)\n",
    "    feature_order = []\n",
    "    feature_error = []\n",
    "    feature_names = []\n",
    "\n",
    "    # Iteración sobre todas las variables\n",
    "    for i in range(len(feature_list)):\n",
    "        idx_try = [val for val in range(len(feature_list)) if val not in feature_order]\n",
    "        iter_error = []\n",
    "\n",
    "        for i_try in idx_try:\n",
    "            useRow = feature_order[:]\n",
    "            useRow.append(i_try)\n",
    "\n",
    "            use_train = x_train[x_train.columns[useRow]]\n",
    "            use_test = x_test[x_train.columns[useRow]]\n",
    "\n",
    "            model.fit(use_train, y_train)\n",
    "            rmsError = numpy.linalg.norm((y_test - model.predict(use_test)), 2)/sqrt(len(y_test))\n",
    "            iter_error.append(rmsError)\n",
    "\n",
    "        pos_best = numpy.argmin(iter_error)\n",
    "        \n",
    "        if len(feature_error) == 0 or (iter_error[pos_best] < feature_error[-1]):\n",
    "            feature_order.append(idx_try[pos_best])\n",
    "            feature_error.append(iter_error[pos_best])\n",
    "            feature_names.append(feature_list[idx_try[pos_best]])\n",
    "            print \"Paso\", len(feature_error), \"variable\", feature_list[idx_try[pos_best]], \"con RMS\", iter_error[pos_best]\n",
    "        else:\n",
    "            return feature_names, feature_error, feature_names\n",
    "\n",
    "    return feature_names, feature_order, feature_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso de la función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 1 variable alcohol con RMS 0.806199994883\n",
      "Paso 2 variable volatile acidity con RMS 0.779728446014\n",
      "Paso 3 variable residual sugar con RMS 0.769803159615\n",
      "Paso 4 variable pH con RMS 0.766920659867\n",
      "Paso 5 variable density con RMS 0.761928889922\n",
      "Paso 6 variable total sulfur dioxide con RMS 0.761166510045\n",
      "Paso 7 variable fixed acidity con RMS 0.760413555836\n",
      "Paso 8 variable sulphates con RMS 0.76036166111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['alcohol',\n",
       "  'volatile acidity',\n",
       "  'residual sugar',\n",
       "  'pH',\n",
       "  'density',\n",
       "  'total sulfur dioxide',\n",
       "  'fixed acidity',\n",
       "  'sulphates'],\n",
       " [0.80619999488306071,\n",
       "  0.77972844601369184,\n",
       "  0.76980315961545764,\n",
       "  0.76692065986717917,\n",
       "  0.76192888992167362,\n",
       "  0.76116651004457658,\n",
       "  0.76041355583597514,\n",
       "  0.76036166111015968],\n",
       " ['alcohol',\n",
       "  'volatile acidity',\n",
       "  'residual sugar',\n",
       "  'pH',\n",
       "  'density',\n",
       "  'total sulfur dioxide',\n",
       "  'fixed acidity',\n",
       "  'sulphates'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy \n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "from math import *\n",
    "\n",
    "wine = pd.read_csv('winequality-white.csv', sep = ';') # primero hay que vargar los datos\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Separación de la variable objetivo y las explicativas\n",
    "target = 'quality'\n",
    "features = list(wine.columns)\n",
    "features.remove('quality')\n",
    "\n",
    "x = wine[features]\n",
    "y = wine[target]\n",
    "\n",
    "# Obtencion del conjunto de datos para validación\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "forward_regression(x, y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Stepwise Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_regression(x, y):\n",
    "    # Obtencion del conjunto de datos para validación\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    # Modelo para realizar los ajustes\n",
    "    model = LinearRegression()\n",
    "\n",
    "    feature_order = range(len(features))\n",
    "    feature_error = []\n",
    "    feature_names = []\n",
    "\n",
    "    for i in range(len(features)-1):\n",
    "        idx_try = [val for val in range(len(features)) if val in feature_order]\n",
    "        iter_error = []\n",
    "\n",
    "        for i_try in idx_try:\n",
    "            useRow = feature_order[:]\n",
    "            useRow.remove(i_try)\n",
    "\n",
    "            use_train = x_train[x_train.columns[useRow]]\n",
    "            use_test = x_test[x_train.columns[useRow]]\n",
    "\n",
    "            model.fit(use_train, y_train)\n",
    "            rmsError = numpy.linalg.norm((y_test - model.predict(use_test)), 2)/math.sqrt(len(y_test))\n",
    "            iter_error.append(rmsError)\n",
    "\n",
    "        pos_best = numpy.argmin(iter_error)\n",
    "        \n",
    "        feature_order.remove(idx_try[pos_best])\n",
    "        feature_names.append(idx_try[pos_best])\n",
    "        feature_error.append(iter_error[pos_best])\n",
    "\n",
    "    for i in range(len(features)-1):\n",
    "        print \"Paso\", i, \"se ha eliminado la variable\", features[feature_names[i]], \"con un error\", feature_error[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso de la función: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 0 se ha eliminado la variable alcohol con un error 0.758889454561\n",
      "Paso 1 se ha eliminado la variable free sulfur dioxide con un error 0.75656298951\n",
      "Paso 2 se ha eliminado la variable chlorides con un error 0.756490702802\n",
      "Paso 3 se ha eliminado la variable total sulfur dioxide con un error 0.756566868955\n",
      "Paso 4 se ha eliminado la variable citric acid con un error 0.756679887062\n",
      "Paso 5 se ha eliminado la variable sulphates con un error 0.763313871596\n",
      "Paso 6 se ha eliminado la variable fixed acidity con un error 0.770160328774\n",
      "Paso 7 se ha eliminado la variable pH con un error 0.781445127639\n",
      "Paso 8 se ha eliminado la variable volatile acidity con un error 0.807255422105\n",
      "Paso 9 se ha eliminado la variable residual sugar con un error 0.843270109824\n"
     ]
    }
   ],
   "source": [
    "backward_regression(x, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Vemos como se están eliminando variables por orden de la magnitud del error, de mayor a menor. A partir de cierto momento quitar variables no provoca ya un desenso del error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
